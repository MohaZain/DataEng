{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "* Data is money and in a day with thousand and thousand of data to process, there is some tool that will suit perfectly with a large amount of data such as [spark](https://spark.apache.org/) and [hadoop](https://hadoop.apache.org/) in this project i will be using Spark to transform [I94 Immigration Data](https://www.trade.gov/national-travel-and-tourism-office) and [World Temperature Data](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data) to [star schema](https://searchdatamanagement.techtarget.com/definition/star-schema) and perform the nasscary step To be ready to query multiple analytics questions.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import DateType, StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "* Dataset scope will be in two different datasets with more than one million records, and then create fact and dimension table to be able to analyze the data and find insigit by using spark to help process a large amount of data.\n",
    "#### Describe and Gather Data \n",
    "* `I94 Immigration Data`: This data comes from the US National Tourism and Trade Office This is where the data comes from [here](https://travel.trade.gov/research/reports/i94/historical/2016.html).\n",
    "* `World Temperature Data`: This dataset came from [Kaggle](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data) contain monthly average temperature for different cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate',\n",
       "       'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count',\n",
       "       'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu',\n",
       "       'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline',\n",
       "       'admnum', 'fltno', 'visatype'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df2 = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "imm_df = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imm_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "* Exploring the data set using pyspark to find any duplicated or null recored to clean them\n",
    "#### Cleaning Steps\n",
    "\n",
    "* Remove any duplicated data.\n",
    "* Change the column name to clearer names.\n",
    "* Transform SAS date to datetime.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "fact_imm = imm_df.select(['cicid','i94yr','arrdate','depdate','i94mode','fltno']).dropDuplicates()\n",
    "\n",
    "# fact_imm.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_imm.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cicid', 'i94yr', 'arrdate', 'depdate', 'i94mode', 'fltno']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_imm.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: double (nullable = true)\n",
      " |-- year: double (nullable = true)\n",
      " |-- arrival_date: double (nullable = true)\n",
      " |-- departure_date: double (nullable = true)\n",
      " |-- mode: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# overwrite column name \n",
    "old_column = fact_imm.schema.names\n",
    "new_columns = ['id', 'year', 'arrival_date', 'departure_date', 'mode','fltno']\n",
    "\n",
    "fact_imm = reduce(lambda fact_imm, idx: fact_imm.withColumnRenamed(old_column[idx], new_columns[idx]), range(len(old_column)), fact_imm)\n",
    "\n",
    "\n",
    "fact_imm.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Transform SAS date to datetime.\n",
    "def convert_SAS_to_date(date):\n",
    "    if date is not None:\n",
    "        return pd.to_timedelta(date, unit='D') + pd.Timestamp('1960-1-1')\n",
    "    \n",
    "convert_SAS_to_date_udf = udf(convert_SAS_to_date, DateType())\n",
    "fact_imm = fact_imm.withColumn('arrival_date', convert_SAS_to_date_udf(col('arrival_date')))\n",
    "fact_imm = fact_imm.withColumn('departure_date', convert_SAS_to_date_udf(col('departure_date')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------------+--------------+----+-----+\n",
      "|   id|  year|arrival_date|departure_date|mode|fltno|\n",
      "+-----+------+------------+--------------+----+-----+\n",
      "|314.0|2016.0|  2016-04-01|    2016-04-11| 1.0|00275|\n",
      "|425.0|2016.0|  2016-04-01|    2016-04-02| 1.0|00097|\n",
      "|496.0|2016.0|  2016-04-01|    2016-04-04| 1.0|00065|\n",
      "|703.0|2016.0|  2016-04-01|    2016-06-27| 1.0|00246|\n",
      "|881.0|2016.0|  2016-04-01|    2016-04-09| 1.0|02067|\n",
      "+-----+------+------------+--------------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_imm.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_immigrant = imm_df.select(['cicid','i94cit','i94res','gender','biryear']).dropDuplicates()\n",
    "\n",
    "dim_immigrant.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cicid', 'i94cit', 'i94res', 'gender', 'biryear']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_immigrant.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: double (nullable = true)\n",
      " |-- citizen: double (nullable = true)\n",
      " |-- residence: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- year_of_birth: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change column name\n",
    "old_column = dim_immigrant.schema.names\n",
    "new_columns = ['id', 'citizen', 'residence', 'gender', 'year_of_birth']\n",
    "\n",
    "dim_immigrant = reduce(lambda dim_immigrant, idx: dim_immigrant.withColumnRenamed(old_column[idx], new_columns[idx]), range(len(old_column)), dim_immigrant)\n",
    "\n",
    "\n",
    "dim_immigrant.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+---------+------+-------------+\n",
      "|   id|citizen|residence|gender|year_of_birth|\n",
      "+-----+-------+---------+------+-------------+\n",
      "| 16.0|  101.0|    101.0|  null|       1988.0|\n",
      "| 84.0|  103.0|    103.0|     M|       1994.0|\n",
      "|536.0|  103.0|    103.0|     M|       1956.0|\n",
      "|670.0|  103.0|    124.0|     M|       1979.0|\n",
      "|681.0|  103.0|    112.0|     F|       1955.0|\n",
      "+-----+-------+---------+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_immigrant.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('./I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "    f_content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def code_mapper(file, idx):\n",
    "    f_content2 = f_content[f_content.index(idx):]\n",
    "    f_content2 = f_content2[:f_content2.index(';')].split('\\n')\n",
    "    f_content2 = [i.replace(\"'\", \"\") for i in f_content2]\n",
    "    dic = [i.split('=') for i in f_content2[1:]]\n",
    "    dic = dict([i[0].strip(), i[1].strip()] for i in dic if len(i) == 2)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94cit_res = code_mapper(f_content, \"i94cntyl\")\n",
    "# i94cit_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_code = pd.DataFrame(list(i94cit_res.items()), columns=['code', 'country'])\n",
    "dim_country= spark.createDataFrame(country_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|code|             country|\n",
      "+----+--------------------+\n",
      "| 582|MEXICO Air Sea, a...|\n",
      "| 236|         AFGHANISTAN|\n",
      "| 101|             ALBANIA|\n",
      "| 316|             ALGERIA|\n",
      "| 102|             ANDORRA|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_country.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dim_airline = imm_df.select(['fltno','airline']).dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|fltno|airline|\n",
      "+-----+-------+\n",
      "|00446|     LH|\n",
      "|00623|     FI|\n",
      "|00229|     UP|\n",
      "|00008|     AV|\n",
      "|04400|     YX|\n",
      "+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_airline.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11942"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_airline.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Temperture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "dim_temp = spark.read.option(\"header\", True).csv(fname)\n",
    "\n",
    "\n",
    "dim_temp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove record that contail null value in both AverageTemperature and AverageTemperatureUncertainty\n",
    "\n",
    "dim_temp = dim_temp.filter(dim_temp.AverageTemperature.isNotNull() & dim_temp.AverageTemperatureUncertainty.isNotNull())\n",
    "\n",
    "dim_temp = dim_temp.select(['dt','AverageTemperature','AverageTemperatureUncertainty','City','Country','Latitude', 'Longitude']).dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "* Star schema are work optimally for data warehouses, BI use and OLAP in that help our goal. \n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "* 1. Extract the data from the provided sources above.\n",
    "* 2. Clean and preprocess the data.\n",
    "    * Remove any duplicated data.\n",
    "    * Change the column name to clearer names.\n",
    "    * Transform SAS date to datetime.\n",
    "    * remove null in temperture if both AverageTemperature and AverageTemperatureUncertainty Null.\n",
    "* 3. Transform imm_df to fact table and dimensional.\n",
    "* 4. Transform temp_df to dimensional table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------------+--------------+----+-----+\n",
      "|   id|  year|arrival_date|departure_date|mode|fltno|\n",
      "+-----+------+------------+--------------+----+-----+\n",
      "|314.0|2016.0|  2016-04-01|    2016-04-11| 1.0|00275|\n",
      "|425.0|2016.0|  2016-04-01|    2016-04-02| 1.0|00097|\n",
      "|496.0|2016.0|  2016-04-01|    2016-04-04| 1.0|00065|\n",
      "|703.0|2016.0|  2016-04-01|    2016-06-27| 1.0|00246|\n",
      "|881.0|2016.0|  2016-04-01|    2016-04-09| 1.0|02067|\n",
      "+-----+------+------------+--------------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write code here\n",
    "fact_imm.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_immigrant.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---------+------+-------------+\n",
      "|    id|citizen|residence|gender|year_of_birth|\n",
      "+------+-------+---------+------+-------------+\n",
      "|  16.0|  101.0|    101.0|  null|       1988.0|\n",
      "|  84.0|  103.0|    103.0|     M|       1994.0|\n",
      "| 536.0|  103.0|    103.0|     M|       1956.0|\n",
      "| 670.0|  103.0|    124.0|     M|       1979.0|\n",
      "| 681.0|  103.0|    112.0|     F|       1955.0|\n",
      "|1139.0|  104.0|    104.0|     M|       2012.0|\n",
      "|1633.0|  104.0|    104.0|     M|       1958.0|\n",
      "|2096.0|  105.0|    105.0|     F|       1968.0|\n",
      "|2344.0|  107.0|    107.0|     F|       2010.0|\n",
      "|2531.0|  107.0|    107.0|     M|       1983.0|\n",
      "|2615.0|  107.0|    107.0|     M|       1990.0|\n",
      "|2913.0|  108.0|    108.0|  null|       1966.0|\n",
      "|2930.0|  108.0|    108.0|     M|       1969.0|\n",
      "|3378.0|  108.0|    108.0|     M|       1967.0|\n",
      "|3425.0|  108.0|    108.0|  null|       1985.0|\n",
      "|3749.0|  108.0|    438.0|     M|       1963.0|\n",
      "|4042.0|  110.0|    110.0|     F|       1991.0|\n",
      "|4109.0|  110.0|    110.0|     F|       1985.0|\n",
      "|4932.0|  111.0|    111.0|  null|       1978.0|\n",
      "|5164.0|  111.0|    111.0|     M|       1989.0|\n",
      "+------+-------+---------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_immigrant.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|code|             country|\n",
      "+----+--------------------+\n",
      "| 582|MEXICO Air Sea, a...|\n",
      "| 236|         AFGHANISTAN|\n",
      "| 101|             ALBANIA|\n",
      "| 316|             ALGERIA|\n",
      "| 102|             ANDORRA|\n",
      "| 324|              ANGOLA|\n",
      "| 529|            ANGUILLA|\n",
      "| 518|     ANTIGUA-BARBUDA|\n",
      "| 687|           ARGENTINA|\n",
      "| 151|             ARMENIA|\n",
      "| 532|               ARUBA|\n",
      "| 438|           AUSTRALIA|\n",
      "| 103|             AUSTRIA|\n",
      "| 152|          AZERBAIJAN|\n",
      "| 512|             BAHAMAS|\n",
      "| 298|             BAHRAIN|\n",
      "| 274|          BANGLADESH|\n",
      "| 513|            BARBADOS|\n",
      "| 104|             BELGIUM|\n",
      "| 581|              BELIZE|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_country.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fact_imm.createOrReplaceTempView(\"fact_imm\")\n",
    "dim_immigrant.createOrReplaceTempView(\"dim_immigrant\")\n",
    "dim_country.createOrReplaceTempView(\"dim_country\")\n",
    "dim_airline.createOrReplaceTempView(\"dim_airline\")\n",
    "dim_temp.createOrReplaceTempView(\"dim_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>gender</th>\n",
       "      <th>citizen_country</th>\n",
       "      <th>residence_country</th>\n",
       "      <th>airline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1434764.0</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>2016-05-19</td>\n",
       "      <td>M</td>\n",
       "      <td>CAYMAN ISLANDS</td>\n",
       "      <td>CAYMAN ISLANDS</td>\n",
       "      <td>YNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1434763.0</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>M</td>\n",
       "      <td>CAYMAN ISLANDS</td>\n",
       "      <td>CAYMAN ISLANDS</td>\n",
       "      <td>YNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>669198.0</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>M</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>YNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>873485.0</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>M</td>\n",
       "      <td>ISRAEL</td>\n",
       "      <td>ISRAEL</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>873485.0</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>M</td>\n",
       "      <td>ISRAEL</td>\n",
       "      <td>ISRAEL</td>\n",
       "      <td>LH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>873485.0</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>M</td>\n",
       "      <td>ISRAEL</td>\n",
       "      <td>ISRAEL</td>\n",
       "      <td>CH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3372894.0</td>\n",
       "      <td>2016-04-18</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>M</td>\n",
       "      <td>ISRAEL</td>\n",
       "      <td>ISRAEL</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3372894.0</td>\n",
       "      <td>2016-04-18</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>M</td>\n",
       "      <td>ISRAEL</td>\n",
       "      <td>ISRAEL</td>\n",
       "      <td>LH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3372894.0</td>\n",
       "      <td>2016-04-18</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>M</td>\n",
       "      <td>ISRAEL</td>\n",
       "      <td>ISRAEL</td>\n",
       "      <td>CH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3540945.0</td>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>2016-05-04</td>\n",
       "      <td>F</td>\n",
       "      <td>ISRAEL</td>\n",
       "      <td>ISRAEL</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id arrival_date departure_date gender citizen_country  \\\n",
       "0  1434764.0   2016-04-08     2016-05-19      M  CAYMAN ISLANDS   \n",
       "1  1434763.0   2016-04-08     2016-04-23      M  CAYMAN ISLANDS   \n",
       "2   669198.0   2016-04-04     2016-04-15      M  UNITED KINGDOM   \n",
       "3   873485.0   2016-04-05     2016-04-17      M          ISRAEL   \n",
       "4   873485.0   2016-04-05     2016-04-17      M          ISRAEL   \n",
       "5   873485.0   2016-04-05     2016-04-17      M          ISRAEL   \n",
       "6  3372894.0   2016-04-18     2016-05-01      M          ISRAEL   \n",
       "7  3372894.0   2016-04-18     2016-05-01      M          ISRAEL   \n",
       "8  3372894.0   2016-04-18     2016-05-01      M          ISRAEL   \n",
       "9  3540945.0   2016-04-19     2016-05-04      F          ISRAEL   \n",
       "\n",
       "  residence_country airline  \n",
       "0    CAYMAN ISLANDS     YNT  \n",
       "1    CAYMAN ISLANDS     YNT  \n",
       "2    UNITED KINGDOM     YNT  \n",
       "3            ISRAEL    None  \n",
       "4            ISRAEL      LH  \n",
       "5            ISRAEL      CH  \n",
       "6            ISRAEL    None  \n",
       "7            ISRAEL      LH  \n",
       "8            ISRAEL      CH  \n",
       "9            ISRAEL    None  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT  fa.id, \n",
    "        fa.arrival_date, \n",
    "        fa.departure_date, \n",
    "        di.gender, \n",
    "        dc.country as citizen_country, \n",
    "        dc2.country as residence_country, \n",
    "        da.airline\n",
    "FROM \n",
    "     fact_imm      fa,\n",
    "     dim_immigrant di,\n",
    "     dim_country   dc,\n",
    "     dim_country   dc2,\n",
    "     dim_airline   da \n",
    "     WHERE \n",
    "            fa.id == di.id\n",
    "            and Int(di.citizen) == dc.code\n",
    "            and Int(di.residence) == dc2.code \n",
    "            and fa.fltno = da.fltno\n",
    "\n",
    "\"\"\").limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citizen</th>\n",
       "      <th>country</th>\n",
       "      <th>number_of_citizen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.0</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>360157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   citizen         country  number_of_citizen\n",
       "0    135.0  UNITED KINGDOM             360157"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we notice here that the most imiigration are citizen of UNITED KINGDOM \n",
    "spark.sql(\"\"\"\n",
    "SELECT  di.citizen, dc.country, count(di.citizen) as number_of_citizen\n",
    "                            FROM dim_immigrant di,\n",
    "                                 dim_country   dc\n",
    "                            where dc.code = Int(di.citizen)\n",
    "                            group by di.citizen ,dc.country\n",
    "                            order by number_of_citizen desc\n",
    "\n",
    "\"\"\").limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|fltno|airline|\n",
      "+-----+-------+\n",
      "|00446|     LH|\n",
      "|00623|     FI|\n",
      "|00229|     UP|\n",
      "|00008|     AV|\n",
      "|04400|     YX|\n",
      "|00502|     AA|\n",
      "|  151|     EY|\n",
      "|01117|     AA|\n",
      "|00097|     3M|\n",
      "|01520|     AA|\n",
      "|  632|     AM|\n",
      "|  450|     CM|\n",
      "|6604C|     Y4|\n",
      "| 5574|     UA|\n",
      "|01193|     UA|\n",
      "|01669|     UA|\n",
      "|   46|    TOM|\n",
      "|00151|     AA|\n",
      "|  790|     AM|\n",
      "|TGMYS|    *GA|\n",
      "+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_airline.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|  AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+--------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1767-01-01|  -6.297999999999999|                        7.282|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1780-10-01|   8.931000000000001|           2.7680000000000002|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1781-05-01|                11.1|                        3.615|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1784-05-01|              11.536|                         2.89|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1785-04-01|               4.388|                        4.287|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1787-04-01|               4.598|           3.4960000000000004|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1822-06-01|              15.686|           1.9469999999999998|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1839-02-01|-0.00900000000000...|                        1.459|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1873-06-01|              15.329|                         0.55|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1877-06-01|              14.967|                        1.893|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1878-04-01|               7.381|                        0.701|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1883-07-01|  17.340999999999998|                          0.6|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1894-01-01| 0.24999999999999994|                        0.568|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1895-12-01|-0.01700000000000...|                         0.51|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1918-02-01|  0.7679999999999999|                        0.306|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1931-05-01|  12.004000000000001|          0.27399999999999997|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1933-04-01|               6.063|                        0.295|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1959-11-01|   5.337000000000001|          0.23199999999999998|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1775-04-01|              10.173|                         1.92|Çorlu| Turkey|  40.99N|   27.69E|\n",
      "|1780-06-01|              21.195|                        4.274|Çorlu| Turkey|  40.99N|   27.69E|\n",
      "+----------+--------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_temp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def check_dublicate(df):\n",
    "    if df.count() == df.dropDuplicates(df.schema.names).count():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def check_record(df):\n",
    "    if df.count() != 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact and dim does not contain any dublicated records\n"
     ]
    }
   ],
   "source": [
    "if check_dublicate(fact_imm) and check_dublicate(dim_immigrant) and check_dublicate(dim_country) and check_dublicate(dim_airline) and check_dublicate(dim_temp):\n",
    "    print(\"Fact and dim does not contain any dublicated records\")\n",
    "else:\n",
    "    print(\"ther is dublicated record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    }
   ],
   "source": [
    "if check_record(fact_imm) and check_record(dim_immigrant) and check_record(dim_country) and check_record(dim_airline) and check_record(dim_temp):\n",
    "    print(\"pass\")\n",
    "else:\n",
    "    print(\"No Record found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "## Immigration data\n",
    "\n",
    "#### Fact Immigration (fact_imm)\n",
    "     |-- id: id\n",
    "     |-- year: year of the arrival\n",
    "     |-- arrival_date: arrival date\n",
    "     |-- departure_date: departure date\n",
    "     |-- mode: mean of travil by (air, sea, land, or not reported)\n",
    "     |-- fltno: flight number\n",
    "     \n",
    "#### Dim Immigrant (dim_immigrant)\n",
    "     Contain immgrant personal information\n",
    "     |-- id: id\n",
    "     |-- citizen: the country of citizenship. in code\n",
    "     |-- residence: the country of residence. in code\n",
    "     |-- gender: person gender\n",
    "     |-- year_of_birth: year of birth\n",
    "     \n",
    "#### Dim Country (dim_country)\n",
    "     Contain code of the country\n",
    "     |-- code: code represent spesifc country\n",
    "     |-- country: country name\n",
    "     \n",
    "#### Dim Airline (dim_airline)\n",
    "     |-- fltno: flight number \n",
    "     |-- airline: airline name\n",
    "     \n",
    "#### Dim Temperture (dim_temp)\n",
    "     |-- dt: date \n",
    "     |-- AverageTemperature: Average Temperature for month\n",
    "     |-- AverageTemperatureUncertainty: Average Temperature Uncertainty\n",
    "     |-- City: city name \n",
    "     |-- Country: Country name\n",
    "     |-- Latitude: Latitude\n",
    "     |-- Longitude: Longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<img src=\"./erdigram1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 5: Complete Project Write Up\n",
    "##### Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "  * Spark has proven to work great with a large amounts of data, also with the simplicity of use.\n",
    "    \n",
    "##### Propose how often the data should be updated and why.\n",
    "  * Could update monthly, Since the Immigration data get updated monthly.\n",
    "\n",
    "### Write a description of how you would approach the problem differently under the following scenarios:\n",
    "\n",
    "##### The data was increased by 100x.\n",
    "  * With increased of data we can relay on Amazon services such as [EMR](https://aws.amazon.com/emr/).\n",
    "  \n",
    "##### The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "  * Using scheduling tool such as airflow will help autmated and scheduling the data pipeline.\n",
    "  \n",
    "##### The database needed to be accessed by 100+ people.\n",
    "  * Consider Amazon service to handle handred or more request simultaneously such as [redshift](https://aws.amazon.com/redshift/) , [Amazon Aurora](https://aws.amazon.com/rds/aurora/?aurora-whats-new.sort-by=item.additionalFields.postDateTime&aurora-whats-new.sort-order=desc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
